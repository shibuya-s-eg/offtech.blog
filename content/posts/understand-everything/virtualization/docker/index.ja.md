---
weight: 4
title: "コンテナとDockerを完全に理解する"
date: 2025-04-30T00:00:00+09:00
lastmod: 2025-04-30T00:00:00+09:00
draft: false
author: "しぶや"
authorLink: "https://github.com/shibuya-s-eg"
description: "コンテナとDockerを完全に理解する。"
images: []
resources:
- name: "featured-image"
  src: "featured-image.png"

tags: ["Virtualization"]
categories: ["Understand-Everything"]
subcategories: ["Virtualization"]

lightgallery: true
---

こんにちは、しぶやです。\
学生時代の研究から始まり、社会人になってからも愛用しているDockerとそもそものコンテナについて、気合をいれてまとめようと思います。


## TL;DR

* コンテナとはコンテナ化されたプロセスである。

## 0　はじめに

### 0.1　コンテナの歴史

コンテナ技術の初期段階として、2008年ごろLXC（Linux Container）が登場しました。
LXCは、2000年代に入ってLinuxに導入されたNamespaceやCgroupsを利用した軽量なコンテナ環境を提供するものです。

その後、2013年ごろ、Dockerが登場し、コンテナ技術が広く知られるようになりました。
DockerはLXCをもとに、コンテナの作成、管理、デプロイを非常に簡単にするツールとして登場しました。
Dockerの登場により、コンテナは非常に使いやすいものとなり、仮想マシンに代わる新しい標準として急速に普及しました。

※ Dockerはあくまでコンテナを管理するためのツールであり、Docker=コンテナではないです。

公式ではDockerを以下のように説明しています。
> Docker は、アプリケーションの開発、出荷、実行の方法に革命をもたらした包括的なプラットフォームとツールスイートを提供します。
> コンテナ化の概念に基づいて構築されており、コンテナの代名詞になるほど単純化されています。

コンテナ関連では近年、Kubernetesにより大規模な分散システムの基盤として使用されたり、サーバーレスコンピューティングに応用されていたりします。

### 0.2　VMとの違い

VMとコンテナの違いはよく聞く話だと思います。
[RedHatの説明](https://www.redhat.com/ja/topics/containers/containers-vs-vms)によるとこの違いは、 「ホストOS上に新たにOSを乗せるているか」と「ホストOS上にコンテナとして隔離されたアプリケーションを乗せているか」の違いによるものです。

この説明の通り、**VMとコンテナの違いはホストのカーネルを共有するか**です。
VMはホストOS上でカーネルの仮想化を行います。
一方で、コンテナはホストのカーネルを共有し、リソースなどを分離します。

これにより、コンテナは**軽量なアプリケーションの実行環境**を実現します。

{{< admonition tip "ハイパーバイザのタイプ" >}}
コンテナから話がそれますが、ハイパーバイザーとそのタイプについて紹介します。

まずは、そもそものハイパーバイザーの定義を見てみましょう。
> ハイパーバイザー (hypervisor) とは、仮想化技術であり、必要なコンピューティング・リソースを分離し、仮想マシン(VM)の作成、実行、管理を可能にするソフトウェアです。ハイパーバイザーは、演算処理、メモリー、ストレージなどのコンピューティング・リソースをプールし、それらを仮想マシン (VM) 間で再割り当てします。このテクノロジーによって仮想化が可能になり、1 つの物理マシンから多数の VM を作成して実行することができます。
> by [redhat](https://www.redhat.com/ja/topics/virtualization/what-is-a-hypervisor)

一般的にもよく使われるものでいうと、VMware Workstationや VirtualBoxがありますね。
商用でも見るものだとVMware ESXiやKVMなどがありますね。

これらのハイパーバイザーは大きく以下の2種類に分けられます。
| 項目 | タイプ1 | タイプ2 |
|-----|--------|-------|
| 実行権限 | 直接 | 間接(ホストOS経由) |
| 制御主体 | ハイパーバイザー自身 | ホストOS |
| 安全性・効率 | 高い | 低い　|

結局タイプ1のハイパーバイザー自身もOSみたいなものが動いているんだから何が違うんだ？って感じです。
ChatGPTによると、「仮想化機能だけを持った(それに特化した)制御ソフト」か「汎用OSで制御ソフトを動かしている」かの違いで区別できるようです。
これは、「カーネルの一部として動作」か「ユーザ空間のアプリケーションとして動作する」かの違いとも言えそうです。

上記の表にある安全性や効率に関しては、タイプ1が「余計なものを動かしていない」ことや「余計なものが含まれていない」ことから来るもののようです。
参考書[2]によると、Linuxカーネルは2000万行以上のコードがあるのに対し、Xenは5万行程度らしいです。

有名な製品をタイプ1とタイプ2で分けると以下のようになります。
* タイプ1
  * VWware ESXi
  * Microsoft Hyper-V
  * Xen
  * KVM
* タイプ2
  * VMware Workstation/Fusion
  * VirtualBox
  * Parallel Desktop

※ KVMやHyper-Vは汎用OS上で、Kernelを拡張してVMを動かすため、タイプ2という意見もあるようです。
{{< /admonition >}}

## 1　コンテナの仕組み

コンテナにはいくつかの欠かせない要素技術があります。
本章では、コンテナの本質を理解するために、それらの要素技術について学習しようと思います。

### 1.1　namespace

NamespaceはLinuxカーネルに組み込まれたプロセス単位でリソースを分離する機能です。
具体的には、特定のプロセスに対し、ネットワークインターフェースを見せたり、プロセスID空間を見せたりできます。

linuxでサポートされているNamespaceには以下のよいなものがあります。
|名前 | 分離対象 | 説明|
|-----------|-------|-----|
|Mount (mnt) | ファイルシステムのマウント状態 | 別のルートディレクトリ構造を持たせることができる|
|UTS|ホスト名、ドメイン名|各Namespaceごとにホスト名が持つことができる|
|IPC|プロセス間通信（共有メモリなど）|通信空間を隔離することができる|
|PID|プロセスID|プロセスID空間を分けることができる|
|Network|ネットワークデバイス、IPアドレス|独立したネットワークスタックを管理できる|
|User|ユーザID、グループID|プロセスに別のUID/GIDマッピングできる|
|Cgroup|cgroupのビュー|制御グループの空間を分離することができる|

では、実際にNamespaceを見てみましょう。

{{< image src="lsns.png" width="800px" height="600px" caption="Namespaceの一覧" >}}

lsnsはNamespaceを表示するためのコマンドです。
TYPEが上で紹介したNamespaceの種類です。
NPROCSはそのNamespaceに所属するプロセス数、PID以降は親プロセスの情報です。

ここで、"sudo lsns"と"lsns"で表示されているNamespaceの数が違うことが分かります。

これは、rootでしかアクセスできないプロセスがいるためです。
よく見るとNPROCSの値も異なることが分かると思います。
Namespaceの情報は各プロセスが持つので、ユーザでは一部のNamespaceに所属するすべてのプロセスが見えず、Namespaceを確認することができないのです。

実際に、/proc配下のアクセス権限を見ると一般ユーザではみれないものがいることが分かります。
（Linuxではプロセス情報はLinuxカーネルが提供する/procから取得できます。）

{{< image src="proc-visibility.png" width="800px" height="600px" caption="/procのアクセス権" >}}

それでは、Namespaceについて詳しく見ていきましょう。
まずはUTSです。

{{< image src="uts.png" width="800px" height="600px" caption="UTS Namespaceの分離" >}}

"unshare"コマンドは新しいNamespaceでプログラムを実行できます。
すなわち、親プロセスである現在のshellからNamespaceを継承せずに子プロセスを作成することができます。

今回の例では、新しいUTS Namespaceを持つshellのプロセスを作成しています。
この場合、新しく作成したプロセス内でhostnameを変更しても、shellが認識しているUTS Namespaceとホスト側の
が認識していUTS Namespaceが異なるため、ホスト側からhostnameコマンドを打っても特に変化はありません。

プロセス空間についても試してみましょう。

{{< image src="pid.png" width="800px" height="600px" caption="PID Namespaceの分離" >}}

プロセス空間を分離してshellプロセスを立ち上げました。
ここで重要なのは、新しいPID Namespaceでは、このshellプロセスがプロセス番号1として扱われていることです。
ホストのPID Namespace絡みた際はプロセス番号1ではありません。

ここでは、プロセスID空間を分離していますが、ホストのプロセス全体が見えています。
これは、psコマンドは/procを見てるだけだからです。
ホストからpsコマンドでアクセスする際と何も変わりません。

コンテナの動きを考えると、プロセスID空間が分離され、新しいプロセスからは何も見えない状況となって欲しいところです。
これを実現するには、作成したshellプロセスから、procファイルシステムを再マウントする必要があります。
```
mount -t proc none /proc
```
上記を実行すると、カーネルが実行した際のプロセスのPID Namespace内のプロセス情報を/procに提供してくれます。
これにより、新しいプロセス空間のプロセスのみが見えるようになり、ホスト側のプロセスは見えなくなります。


コンテナでは、1.3のchrootと合わせてこれを利用しています。

{{< admonition tip "/procの値とNamespace" >}}
/procはアクセス時にアクセスしたプロセスのNamespaceに応じて結果を返すわけではないようです。
正確には、/procをマウントしたプロセスのNamespaceに応じてアクセス時の結果が変わるようです。

すなわち、procファイルシステムのマウント時のPID Namespaceにより、/procの中身が変わります。
{{< /admonition >}}

それでは、mount Namespaceについて見ていきましょう。

{{< image src="mount.png" width="800px" height="600px" caption="mount Namespaceの分離" >}}

"mount --bind"はプロセスにファイルシステムのマウントポイントをバインドし実行するコマンドです。
そもそもプロセスへのマウントとは何でしょうか？
Linuxにおいて各プロセスはファイルシステムのマウントポイントを持っています。
これは、/proc/${pid}/mountsで見ることができます。

{{< image src="proc-mounts.png" width="800px" height="600px" caption="プロセスのマウント情報" >}}

よく分からないものが大量にマウントされていますね。
いずれにせよ、プロセスごとにマウントポイントを持っていることが分かると思います。
これにより、どのプロセスからアクセスするかにより、マウントされているものの見え方が変わります。

Dockerでは、このmount namespaceの分離と1.3で説明するchrootを組み合わせてコンテナ領域の分離を行っています。


続いてNetwork Namespaceです。
Network Namespaceはネットワークインターフェースやルーティングテーブルの分離を行います。
実際に見てみしょう。

{{< image src="unshare-net.png" width="800px" height="600px" caption="Network Namespaceの作成" >}}

上記の例では、新規のNetwork Namespaceを作成し、bashを実行しています。
しかし、これだけでは、仮想インターフェースがないためホストと通信ができません。
ホストと通信できるようにします。

{{< image src="unshare-net-2.png" width="800px" height="600px" caption="仮想NICの作成" >}}

※ 一応、左右で時系列を意識しています。。

これでホストとコンテナが通信できるようになりました。
上記の例では、お互いのNetwork Namespaceで仮想NICを作成し、IPアドレスを割り当てることで通信できるようにしました。
Network Namespaceを分離することにより、各プロセスはNICやルーティングテーブルなど独立したネットワークスタックを保持できていることが分かります。

続いては、User Namespaeです。User Namespaceはプロセスごとにユーザやグループの分離を行います。

新たなUsername Namespaceを作成してみましょう。

{{< image src="user.png" width="800px" height="600px" caption="User Namespaceの作成" >}}

新しいUser Namespaceを作成するとユーザはnobodyになります。

ここでホストのユーザとのマッピングを行います。

{{< image src="user-3.png" width="800px" height="600px" caption="User Namespaceの作成" >}}

{{< image src="user-2.png" width="800px" height="600px" caption="プロセスへのUIDのマッピング" >}}

 時系列が分かりづらくなってしまいましたが、1枚目の画像の前半では、User Namespaceを新たに作成し、bashを起動しています。
その後、2枚目の画像のように、ホストから先程のプロセスにrootのUIDをマッピングしています。
これにより、1枚目の画像の後半のようにプロセスのユーザがrootに置き換わります。

残りはIPC NamespaceとCgroup Namespaceです。

IPC Namespaceは、プロセス間通信を行うために利用されます。
Dockerではコンテナ同士に同じIPC Namespaceを割り当てることで互いに共有メモリにアクセスできるようにします。

{{< image src="ipcs.png" width="800px" height="600px" caption="IPC Namespaceの分離" >}}

Cgroup Namespaceは1.2節で説明するCgroupについて、Cgroupの見える範囲を分離します。
これにより、プロセスは上位のリソース構成を覗けず、独立して動いているように見えます。

{{< image src="cgroup.png" width="800px" height="600px" caption="cgroup Namespaceの分離" >}}

### 1.2　cgroup

CgroupはLinuxカーネルに組み込まれたプロセス単位でリソースを監視/制御する機能です。
具体的には以下のようなことができます。

* リソース使用量のモニタリング
* CPU使用率の制限
* メモリ使用量の制限
* ディスクI/O帯域の制限
* ネットワーク帯域の制限

Cgroupはプロセスをグループにまとめたプロセスグループを作成し、リソース管理のルールを適用することでリソース使用量の管理／制御を行います。

Dockerはコンテナ単位でCgroupのグループを作成し、リソース使用量を管理しているのです！

それでは実際にCgroupを見ていきましょう。

{{< image src="fs-cgroup.png" width="800px" height="600px" caption="Cgroup" >}}

Linuxカーネルは/sys/fs/cgroupに擬似ファイルシステムを作成し、Cgroupに関連する情報を提供します。

{{< admonition tip "擬似ファイルシステムとは" >}}

擬似ファイルシステムとは、実際にファイルのようにカーネル内部の情報にアクセスできるようにする仕組みです。
実際にディスク内部にデータを保存しているわけではなく、リアルタイムにカーネルが情報を生成して応答してくれています。
カーネルAPIみたいな感じですね。

Linuxの擬似ファイルシステムのは以下のようなものがあります。
* /proc\
プロセス情報やシステム情報をファイル形式で提供
* /sys\
デバイスやカーネル内部設定の情報/操作をファイル形式で提供
* /dev\
デバイスファイル

{{< /admonition >}}

実際にCgroupを試してみましょう。

まずは、"stress"コマンドで2GBのメモリを利用するプロセスを動かしてみましょう。

{{< image src="cgroup-nolimit.png" width="1000px" height="800px" caption="負荷の大きいプロセス" >}}

psコマンドの結果からメモリを50%利用していることが分かります。
これに対し、Cgroupを設定して同じことをした場合どうなるか見てみます。

{{< image src="cgroup-oomkiller.png" width="1000px" height="800px" caption="Cgroupで制御されたプロセス" >}}

上記の例では、"/sys/gs/cgroup"に"mylimit"というフォルダを作成し、"memory.max"という名前でメモリの制限値を入力しています。
その後、同フォルダの"cgroup.procs"にプロセス番号を入れながら、先ほどと同じプロセスを動かしています。
結果から、プロセスが強制終了させられていることが分かると思います。
これは、Cgroupでの制限値を超えたことにより、カーネルがプロセスの終了を行ったためです。


### 1.3　chroot/rootfs

chrootはrootディレクトリを変更するコマンドです。
chrootは引数にパスとコマンドを受け取ります。
これにより、指定したパスをルートとして、コマンドを実行します。
ここで、注意が必要なのは、コマンド（により生成されたプロセス）自身もルートより上位のファイルにはアクセスできなくなります。
すなわち、ルートとして指定したパスの配下にコマンド実行に必要なファイルが一式必要です。

実際に、適当なコマンドで試してみましょう。

{{< image src="chroot-1.png" width="1000px" height="800px" caption="chrootの例（エラー）" >}}

配下にbashの実行ファイルがないため、エラーになります。

では、よりdockerを意識してalpineのパッケージを使って試してみましょう。

{{< image src="chroot-2.png" width="1000px" height="800px" caption="chrootの例（エラーなし）" >}}

配下にalpineのパッケージが一式あるため、コマンドを実行できます。
shを実行してみるとルートより上には上がれず、一式のファイルがあるため仮想環境のように感じます。
まさにDockerでコンテナを立てたときのようですね！\
※ ここで、shのpathはどうなっているのか？と感じますね。
chroot時はホストの環境変数は引き継がれ、$pathなどはルートとして設定された位置を起点に検索が行われています。

{{< admonition tip "環境変数" >}}
chrootではホストの環境変数が引き継がれていましたが、dockerで立てたコンテナではホストとは隔離されて別の環境変数が利用できます。
これはどのように実現されているのでしょうか？

これを理解するためには、そもそも環境変数の理解が必要です。
実は、環境変数の実体はメモリ上に保存されており、プロセスごとに保持しています。

{{< image src="environ.png" width="1000px" height="800px" caption="プロセスがもつ環境変数" >}}

上の画像からプロセスが環境変数を持っていることが分かると思います。

確認したように、環境変数はプロセスごとに保持しており、プロセスは他プロセスの環境変数にアクセスすることはできません。
子プロセスは親プロセスの環境変数を引き継ぎ、親プロセスの環境変数のは影響を与えずに自身の環境変数を変更できます。

dockerなどでは、コンテナを生成する際にメインプロセスに引数やDockerfike、コンテナイメージから受け取った環境変数を付与し、コンテナを立ち上げます。
{{< /admonition >}}


### 1.4　コンテナの本質

「結局コンテナって何なの？」と言われた時に何て答えましょう？
個人的には、参考書[2]にあった「コンテナ」=「**コンテナ化されたプロセス**」という表現がしっくりきています。
「Linuxのプロセスをリソースやアクセスできる空間などを分離した上で動かしたもの」がコンテナと言えそうです。

## 2　コンテナイメージ

本性では、コンテナ自身の実体である、イメージとその管理について説明します。

### 2.1　イメージ管理

コンテナレジストリとは、コンテナイメージ全体の保管サーバです。
代表的なレジストリには以下があります。
* Docker Hub...Docker社が運営する、最も有名なパブリックレジストリ
* Github Container Registry...Githubが提供するコンテナレジストリ
* Amazon ECR...AWSが提供するマネージドなレジストリ（AzureやGCPも同様）

コンテナレジストリに対し、レジストリ内の特定の名前空間/プロジェクトごと保存単位をレポジトリと呼びます。
Docker Hubにある公式の"nginx:latest"を例にするとDocker Hubがレジストリであり、nginxがレポジトリ名です。

ここでは、Dockerでデフォルトで利用されるDocker Hubについて調査します。

[Docker Hub](https://www.docker.com/ja-jp/products/docker-hub/)はコンテナ化されたアプリを簡単に保存、管理、デプロイするためのプラットフォームです。
Docker Hubの機能には以下のようなものがあります。
* 無制限のパブリックリポジトリ...無制限のパブリックなリポジトリを利用できます。誰かが作成したカスタムイメージなどもすぐに利用できます。
* プライベート リポジトリ...プライベートリポジトリを作成し、イメージへのアクセス制御を行うことができます。
* 効率的なイメージアクセス...コンテナイメージへの効率的なアクセスと配布をサポート
* Webhook...イメージのプッシュなどのイベントをトリガーに外部に通知を送ることができます。これにより、Docker HubのCI/CDパイプラインとの統合を可能にします。
* 自動テスト...コンテナイメージで自動テストを実行し、問題を早期に発見することができます。
* GitHubとBitbucketの統合...Githubなどと統合し、バージョン管理システムからの直接ビルドと導入を自動化します。
* 同時ビルドと自動ビルド...複数のビルドを同時に実行することができます。


### 2.2　イメージの構成

コンテナ関連の標準仕様は[OCI（Open Container Initiative）](https://opencontainers.org/)で標準化されています。
OCIは2015年にDocker社を含む複数の企業により設立されました。
以下は、OCIで標準化しているものの例です。
* OCI Runtime Specification...コンテナランタイムの標準仕様
* OCI Image Format Specification...コンテナイメージの標準仕様
* OCI Distribution Specification...コンテナイメージの配布に関する標準仕様

Dockerでも利用するコンテナのイメージは[OCI Image Format Specification](https://github.com/opencontainers/image-spec/blob/main/manifest.md)で標準化されているのです。
ここでは、このコンテナイメージについて深ぼって見ていきます。

1.3節のchrootでは、パケージ群をまるごと用意して、コンテナ環境の動作イメージを確認しました。
もちろん、コンテナイメージは単純にパッケージ群をまとめて圧縮しているだけではありません。
ここでは、コンテナイメージの階層構造について学習しようと思います。

コンテナイメージにはLayerという概念があります。
これはUnionFSの仕組みを利用したイメージの構築/管理の仕組みです。
（UnionFSは[ここ](https://christina04.hatenablog.com/entry/2016/01/26/204659)の説明が分かりやすいです。）

Dockerイメージのレイヤの特徴は以下です。
* 読み取り専用のレイヤを積み重ね、最上位に書き込み可能なレイヤを追加する。
* 各レイヤはファイルシステムの差分情報をもつ
* 同じイメージから作成されたコンテナは読み取り専用レイヤを共有する。
* 読み取り専用レイヤはキャッシュされる。

実際にイメージを見てみましょう。

今回は下記Dockerfileをもとにイメージをビルドしていきます。
"myapp/hoge.txt"を持ったイメージをビルドしています。
{{< image src="dockerfile.png" width="800px" height="600px" caption="UbuntuをベースイメージとしたDockerfile" >}}


{{< image src="docker-build.png" width="800px" height="600px" caption="イメージのビルド" >}}

[x/4]となっている部分がレイヤーを表しています。
各レイヤーはDockerfileの各行と一致していることが分かります。
また、レイヤー2では"CASHED"という文字がありキャッシュが利用されていることも分かります。

docker inspectコマンドを利用して、イメージを見てみましょう。

{{< image src="docker-inspect.png" width="1000px" height="800px" caption="inspectコマンド" >}}

イメージ自身はIdをもっており、sha256のハッシュ値となっていることが分かります。
Config: Labelsにはイメージの名前が記載されています。(タグの値がこれなのでしょうか)
RootFSには複数のLayerが記載されていることが分かります。

それでは実際にイメージの中身を見ていきましょう。
ここではイメージをローカルにファイルとして落として展開してみましょう。

{{< image src="image-content.png" width="800px" height="600px" caption="コンテナイメージの展開" >}}

イメージを展開するとLayerが入ったフォルダとindex.json、manifest.jsonなどが現れます。
これは、OCI標準のイメージレイアウトのようです。


{{< admonition tip "ローカルリポジトリの実態" >}}
dockerが管理する情報は/var/lib/dockerにあります。
{{< image src="local-1.png" width="1000px" height="800px" caption="ローカルのDockerの情報" >}}

ローカルのイメージの情報は/var/lib/docker/image/overlay2/imagedb/にあります。
{{< image src="local-2.png" width="1000px" height="800px" caption="ローカルイメージ" >}}
{{< /admonition >}}


各ファイルを見ていきましょう。

{{< image src="image-content-2.png" width="1000px" height="1200px" caption="イメージ内のメタデータ" >}}

イメージの名前の他にmediaTypeでイメージの規格か何かを示しています。
また、platformでCPUアーキテクチャを指定する場合もあるようです。

{{< image src="image-content-3.png" width="1000px" height="800px" caption="イメージ内のレイヤ" >}}

manifest.jsonにLayerのハッシュが記載されており、blobs/sha256にLayerの実体が配置されています。

では、manifest.jsonに記載されている順に各レイヤを展開してみましょう。
まずは、ひとつめのLayerです。

{{< image src="image-content-4.png" width="1000px" height="800px" caption="レイヤの中身１" >}}

一般的なLinuxのファイル構造の一部が現れました。
とはいえ、/etc以外はほとんど何もない状態です。

2番目以降のレイヤも展開してみます。

{{< image src="image-content-5.png" width="1000px" height="800px" caption="レイヤの中身２" >}}

2番目のLayerでは、/tmpや/var/lib/apt/listsも追加されました。

{{< image src="image-content-6.png" width="1000px" height="800px" caption="レイヤの中身３" >}}

3番目のLayerでは、さらに/etcが足されました。

{{< image src="image-content-7.png" width="1000px" height="800px" caption="レイヤの中身４" >}}

4番目のLayerでは、DockerfilenでCOPYを記載したhoge.txtが含まれていました。

これらから分かるように各LayerはDockerfileに記載した各行と対応していることが分かります。
本節の最初に話したとおり、コンテナイメージは読み取り専用のLayerを重ねているのです。

### 2.3　最小化

基本的にイメージは小さいほど良いされます。
この理由として以下のようなことがあります。
* 起動時間の短縮\
コンテナは頻繁にレジストリからイメージをpullしたり、イメージから展開したりします。
イメージのサイズが小さいことはこれらの実行時間が短くなります。
また、ネットワーク経由で行われる動作に関しては、ネットワーク負荷を抑えることにもつながります。
* ストレージの節約\
イメージが小さいことはストレージの節約につながります。
イメージの比較をするためにubuntuとalpineのベースイメージを比較してみました。
ベースイメージを軽量なものにするだけで10分の1程度のイメージサイズになることが分かります。
    * ubunu:latest...78.1MB
    * alpine:latest...7.83MB

* セキュリティ対策\
不要なパッケージが含まれていなければ、攻撃者が攻撃に利用する材料を減らし、攻撃の成功可能性を減らすことにつながります。
* 管理\
余計なパッケージが含まれていなければ、トラブル時などの管理が容易になります。

以上のようにベースイメージを軽量なものにするなどして、コンテナイメージを軽量にすることは様々なメリットがあります。

## 3　Docker実践

ここでは、実際にnginxのコンテナを立てながら1,2章の内容を確認していきます。


まずは、イメージをローカルリポジトリに持ってきます。

{{< image src="pull-nginx.png" width="800px" height="600px" caption="イメージの取得" >}}

デフォルトのDocker Hubからイメージを取得しました。
ログから分かる通り、イメージもレイヤーごとに取得しています。

docker imagesコマンドにより、ローカルリポジトリに存在するイメージを一覧表示することができます。
nginxイメージは何秒前に取得され、サイズはであることが分かります。

取得したイメージを確認してみましょう。

{{< image src="inspect-nginx.png" width="1000px" height="800px" caption="nginxイメージの詳細情報" >}}


docker inspectの結果では、イメージについてより詳細な情報が得られます。
Nginxイメージは192MBであることなどが分かります。

{{< admonition tip "docker pullを実行したときの通信" >}}

{{< image src="docker-pull.png" width="1000px" height="800px" caption="イメージ取得時の通信" >}}

接続先は、"registry-1.docker.io" であった。
{{< /admonition >}}

nginxイメージをベースイメージとして、Dockerfileを書いていきましょう。

{{< image src="nginx-dockerfile.png" width="800px" height="600px" caption="nginx用Dockerfile" >}}

ページのリソースを作成し、そのままイメージをビルドしていきます。

{{< image src="hello-nginx.png" width="800px" height="600px" caption="nginxイメージのビルド" >}}

Dockerfileの各行をレイヤとしてビルドされていることがわかります。
このイメージからnginxをコンテナとして立ち上げていきます。

{{< image src="hellow-nginx-container.png" width="1000px" height="800px" caption="コンテナの起動" >}}

ローカルの8080番ポートとコンテナ内部の80番ポートをつなげて、nginxコンテナを起動しています。

"docker ps"コマンドでコンテナの情報を確認できます。

{{< image src="localhost-8080.png" width="800px" height="600px" caption="" >}}

上記のようにlocalhost:8080にアクセスするとnginxにアクセスできます。

{{< admonition tip "dockerdによるローソケットの開放" >}}

先ほどはホストの8080番ポートを利用しましたが、80番ポートを利用することも可能なのでしょうか？

{{< image src="docker-raw-socket.png" width="800px" height="600px" caption="" >}}

上記のようにホストの80番ポートも問題なく開けられることがわかります。
なぜ、管理者権限を利用せずに開けられのでしょうか？

これは、dockerデーモンが管理者権限で動いており、dockerデーモン経由でポート開放などが行われているからです。

{{< /admonition >}}

各コンテナの情報は"/var/lib/docker/containers/"にあります。

{{< image src="nginx-container-data.png" width="1000px" height="800px" caption="/var/lib/docker/containers" >}}

"/var/lib/docker/containers/${コンテナID}"にはコンテナに関するメタデータやログ情報が保管されています。
実際にnginxのログを見てみましょう。

{{< image src="nginx-container-log.png" width="1000px" height="800px" caption="nginxコンテナのログ" >}}

nginxコンテナの標準出力/標準エラー出力が確認できます。
ここで重要なのは、**このディレクトリはコンテナが消えると削除されることです。**
すなわち、コンテナのログもコンテナがなくなると消えてしまいます。
このため、コンテナのログをコンテナのライフタイムに依存せず管理したい場合は、別の仕組みで管理する必要があります。

"/var/lib/docker/overlay2/"ではローカルリポジトリにある各レイヤの実体が保管されています。

{{< image src="overlay2.png" width="1000px" height="800px" caption="ローカルリポジトリのレイヤの実体の保管" >}}

こちらはVMでなく僕自身の私用端末で実行した結果なので、ごみがたくさん混じっています。。

Cgroupも確認していきましょう。

{{< image src="container-info.png" width="1000px" height="800px" caption="nginxコンテナのCgroup" >}}

コンテナに限らず、Cgroupの情報は"/proc/${PID}/cgroup/"からアクセスできます。
このため、nginxコンテナのプロセスIDを取得し、"/proc/${nginx pid}/cgroup"からnginxのCgroup情報を確認しています。

実際にファイルの中身を確認してみます。

{{< image src="container-info-2.png" width="1000px" height="800px" caption="nginxコンテナのCgroup詳細" >}}

"memor.current"はそのプロセス（nginxコンテナ）の現在のメモリ使用量です。22MB利用していることがわかります。
同様に"cpu.stat"はcpu使用量、"pids.current"はそのコンテナが生成したプロセス数を表しています。

## 4　コンテナセキュリティ

### 4.1　Capability

管理者権限を与えずに、最小権限の原則に則り、動作に必要な権限のみを与えるやつです。
以下は「Linuxのアクセス制御を完全に理解する」からの抜粋です。

>capabilityは従来のルート権限を分割したものです。
>ルート権限という強く広い権限を与えるではなく、capabilityによる一部の強い権限を与えることにより、最小権限の原則に従うことができます。
>
>実際に例を見てみましょう。以下はubuntuにもともと入っている"ping"です。
>
>{{< image src="ppping.png" width="800px" height="600px" caption="pingの権限" >}}
>
>特にsetuidが付与されているわけでもなく、一般ユーザとして実行できるように見えます。
>実際に、pingは一般ユーザでも実行できると思います。
>
>では、このコマンドを自分のものとしてコピーして実行してみましょう。
>一般ユーザとして実行できているファイルなので、コピーができれば問題なく動作するはずです。
>
>{{< image src="ping_caps_error.png" width="800px" height="600px" caption="ソケットエラー" >}}
>
>エラーになりました。
>ローソケットの操作が許可されていないと怒られており、"capability"か"setuid"がないと言われています。
>
>これは、"ping"がローソケットを利用しており、その権限がないためエラーが出ているのです。
>では、もともと入っていた"ping"を見てみましょう。
>
>{{< image src="ping_caps.png" width="800px" height="600px" caption="pingのcapability" >}}
>
>"cap_net_raw=ep"とあり、ローソケットを利用するためのcapabilityが割り当てられていることが分かります。\
>※ e=Effectve, p=Permitted を意味してます。
>
>これにより、setuidを利用せずにローソケットの利用しており、pingに脆弱性があったとしても権限昇格などの危険性が緩和されます。
>
>基本的なアクセス制御から復習したい方は「Linuxのアクセス制御を完全に理解する」をお勧めします！

Dockerでは、特定のCapabilityだけをコンテナに割り当てることで、より厳密な最小権限の割当を実現しています。

### 4.2　コンテナroot

多くのコンテナはデフォルトでrootユーザのプロセスとして実行されます。
これは、**コンテナからホストへエスケープされた際にそのまま権限昇格される**ため非常に危険です。
OSSの公式イメージなどはデフォルトで実行時のユーザを変更してくれていますが、それがない場合はDockerfileでUSER命令を実行するなどして実行ユーザを変えることが得策です。

上記では、コンテナのプロセスがそのコンテナ自身のUserネームスペース内でrootユーザとして実行されることを説明しています。
しかし、3章で確認したように、通常コンテナには最低限のCapabilityしか付与されておらず、プロセスがアクセスできるリソースも制限されています。
そのため、「ホストのrootのようにコンテナ内から何でもできる」というわけではありません。

ここで、最も注意すべき点は"--privileged"というオプションです。
これは特権を与えてコンテナを動かすためのオプションであり、数多くのCapabilityをコンテナに与えます。

"--privileged"オプションが付与されている場合、コンテナ内からホストのファイルシステムをマウントして、ホストの環境にアクセスすることもできます。
"--privileged"は非常に危険なオプションであり、基本的には利用を避けるべきです。
代替手段として、必要なCapabilityのみを個別に付与するなどの対策を行うと良いでしょう。

### 4.3　イメージ

セキュリティに関してコンテナイメージで気にすることに以下のようなものがあります。
* 信頼のあるベースイメージの利用\
コンテナのイメージは非常に多く存在します。
闇雲にイメージを利用していると、悪意のある攻撃者がバックドアを仕掛けたイメージなどを利用してしまう可能性もあります。
重要なことは信頼のあるベースイメージを利用することです。
公式のイメージのみを利用したり、イメージの署名検証やハッシュ値の比較を実施したりすることが大切です。
* 脆弱性対応\
通常のソフトウェアと同じく、コンテナでも脆弱性への対応が必要です。
コンテナに対しイメージスキャンを行うなどして、運用として脆弱性対応を行うことが大切です。
* 設定ミス防止\
イメージの設定ミスにより、脆弱なコンテナを運用してしまう可能性があります。
また、本来イメージに埋め込むべきでない機密情報などをビルド時にイメージに埋め込んでしまうと情報漏洩につながる可能性があります。
開発者が注意することが一番の対策ですが、イメージスキャンを行うことで設定ミスを検出できる可能性もあります。
* イメージの最小化\
イメージに必要なものだけを含めることは、アタックサーフェスを縮小することにつながります。
* デプロイの承認\
コンテナはビルド時のみでなく、デプロイメント時にもセキュリティ上問題がないか確認を行うことが大切です。
悪意のあるイメージが実行されないよう、信頼されたイメージかどうかや署名が行われているかを確認し、条件を満たした場合のみデプロイできる環境を構築することが大切です。

### 4.4　リソース共有

Dockerはデフォルトで1章で取り上げたようなリソースを分離してコンテナを実行してくれます。
しかし、ユーザの設定によってはコンテナにホストのリソースを共有しすぎることにより不用意なホストへのアクセスの危険性が生まれます。

一つの例としてボリュームがあります。
極端な例としてはコンテナにホストのルートディレクトリをボリュームとしてマウントした場合、コンテナ内から自由にホストにリソースにアクセスできます。

ボリュームをはじめ、ネームスペースなどコンテナのアクセス範囲を追加で設定する場合は必要最小限に抑えることが大切です。
これによりコンテナが攻撃を受けた際の影響範囲を抑えることができます。



## 5　Dockerのメリット/デメリット

本章ではDockerのメリットやデメリットを主にVMと比較したときの観点で紹介していきます。

### 5.1　メリット

* 軽量性\
コンテナはあくまでプロセスにすぎません。
VMのやうにハードウェアをエミュレートしたり、ゲスト用に新たなカーネルを動作させたりもしません。
これにより、専用にVMを立ててアプリケーションを動かす場合と比較し、軽量に動作させることができます。
また、起動時間が非常に短いことも大きなメリットと言えます。

* 再現性/移行性\
コンテナは自身のパッケージ群を持っています。
すなわち、Dockerfileと参照するイメージが同じであれば、いつでもパッケージ群でプロセスが動くということです。
これにより、開発者は開発環境が違っても同じアプリケーション環境での開発、デプロイを実現することができます。

* 環境構築の迅速化\
コンテナはDocker Hubなどを通して非常に多くのイメージが展開されています。
また、追加のパッケージ等もDockerfileにコードとして記載することで容易にインストールできます。
これにより、VMを立てて必要なパッケージをインストール/設定していく場合と比較し、より迅速に環境構築を行うことができると言えます。

* リソースの節約\
VM単位でリソースを確保せず、アプリケーション単位でリソースを確保できるためリソースの節約になる可能性があります。
具体的には、クラウドでのコンテナ利用があります。
VMで固定のリソースを確保した場合は、実際にリソースを利用していなくても課金されますが、コンテナであれば使ったリソース分のみの課金ですみます。

* ホストを汚さない\
これは、個人的に大きなメリットだと持っている点です。
Dockerfileはいつでも同じものを作れる設計書です。
リソースを外から取ってこれる場合は、テキストファイルのみあれば、いつでもすぐに同じ環境を作れます。
これは、ホスト環境も汚れずにストレージ容量も取らないため検証用の環境だったりを手元に保管しておくうえで非常に便利です。

* アタックサーフェスの縮小
アプリケーションをコンテナとして必要最小限の権限のみをつけて実行することで、アタックサーフェスを縮小できます。
コンテナは様々なリソースを分離し、必要なcapabilityのみを持たせることで、攻撃対象を縮小するだけでなく、攻撃を受けた際の影響を抑えてくれます。
アプリケーションユーザも変えずに何でもかんでもsudoでアプリケーションを動かす場合と比較し、非常に堅牢であると言えます。

### 5.2　デメリット

* VMと比較し、分離レベルが低い\
コンテナはホストのカーネルを共有するため、VMと比較し分離レベルは低いです。
これにより、設定が不適切であったり、脆弱性があったりするとホストに影響を与える可能性があります。
（決して「コンテナ=危険」というわけではないです。一方で、専用の特化したタイプ1のハイパーバイザーほど安全とは言えないでしょう。）

* ホストと同じOSしか動かせない\
ホストのカーネルを共有するため、ホストと同じOSしか動かせません。
WindowsであればWSLなどでLinuxを動かし、そこでコンテナを動かす必要があります。
Linux環境では、Windowsのコンテナが動かせません。

* 状態管理が難しい\
コンテナは使い捨てが前提です。
状態管理やログの保管などはコンテナ外の別の仕組みと組み合わせて実装する必要があります。

* オーバヘッド\
Dockerで動かす場合はコンテナ化の処理とコンテナ関連の管理が必要となるため、ホストで直接動かすよりは負荷が増えます。

## 6　Dockerのユースケースとアーキテクチャ

### 6.1　環境統一

5.1節で述べたように、Dockerで開発を行うことで開発環境の差異をなくすことができます。
同じDockerfileを共有することで同じパッケージ群でアプリケーションを動かすことができるからです。
また、これは開発者の環境だけでなく、本番環境でも同じアプリケーション環境でアプリケーションを動かせるというメリットがあります。

### 6.2　CI/CD
CI/CD（継続的インテグレーション/継続的デリバリー）はコンテナで開発を行う大きなメリットです。

CIは開発時にコードを共有のレポジトリで管理し、コード配置後には自動でビルドやテストを行う開発手法です。
一つの例として、githubとクラウドを連携させるなどして、チームでコード開発からビルド/テストまでを統一的に行うものがあります。
CDはCIに成功した場合などにそのまま本番環境に自動デプロイする手法です。

これにより、開発から本番環境への適用までのプロセスを効率化できます。
CI/CDのような開発と運用を統合した考え方をDevOpsといいます。

### 6.3　Kubernetes

Kubernetesはコンテナの管理を行うOSSのコンテナプラットフォームです。
Kubernetesでコンテナ管理を行うことで以下のことを実現できます。
* コンテナの自動デプロイと管理
* IaCによるコンテナの管理
* 自己修復
* 自動スケーリング
* ローリングアップデートやロールバック
など

Kubernetesについては、「Kubernetesについて完全に理解する」で詳しく書こうと思います。


## 7　まとめ

本記事では、dockerをベースにコンテナの仕組みからコンテナのユースケースまで解説しました。
今後もkubernetesを始めとしたコンテナによるマイクロサービスはますます増えると思われます。
仕組みを理解した上でメリットデメリットを判断し、有効活用していきましょう。

## 参考

[1] [docker](https://www.docker.com/)\
[2] [コンテナセキュリティ　コンテナ化されたアプリケーションを保護する要素技術 ](https://www.amazon.co.jp/%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%82%BB%E3%82%AD%E3%83%A5%E3%83%AA%E3%83%86%E3%82%A3-%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E5%8C%96%E3%81%95%E3%82%8C%E3%81%9F%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E4%BF%9D%E8%AD%B7%E3%81%99%E3%82%8B%E8%A6%81%E7%B4%A0%E6%8A%80%E8%A1%93-Liz-Rice/dp/4295016403)\
[3] [コンテナと VM](https://www.redhat.com/ja/topics/containers/containers-vs-vms)\
[4] [docker hub](https://hub.docker.com/)\
[5] [docker hub クラウドネイティブなソフトウェアの導入を簡単に](https://www.docker.com/ja-jp/products/docker-hub/)\
[6] [dockerが使うUnionFileSystemを僕なりに解釈した](https://namu-r21.hatenablog.com/entry/2016/10/27/013006)\
[7] [コンテナセキュリティ コンテナ化されたアプリケーションを保護する要素技術](https://book.impress.co.jp/books/1122101051)\
[8] [コンテナの標準仕様について調査してみた件](https://qiita.com/mamomamo/items/448a8edf6d4ccfc22bbd)\
[9] [OCI Image Format Specification](https://github.com/opencontainers/image-spec)\
[10] [Dockerコンテナのレイヤ構造とは？](https://qiita.com/okmtz/items/f8231c83134a6363647b)\
[11] [UnionFS で Docker のレイヤ構造を理解する](https://christina04.hatenablog.com/entry/2016/01/26/204659)\
[12] [Open Container Initiative](https://opencontainers.org/)
